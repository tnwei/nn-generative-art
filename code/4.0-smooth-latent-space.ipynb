{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Touring the latent space, but smoother"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah so this needs to be smoother. Had previous experiments where the weights were perturbed in one direction, which produces the intended smooth transition effect. The key here is that the direction of travel needs to be fixed for a time duration so that it is sufficiently smooth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travelling from point to point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An idea comes to mind. Starting from a point in the latent space, bounded at min and max values, a random point in the latent space is picked, and a path is generated for the next N steps required to move in that direction until the point is arrived at, of which then a new point can be picked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptually we start with two points, start and end\n",
    "start = np.random.uniform(low=-1, high=1, size=(2,))\n",
    "end = np.random.uniform(low=-1, high=1, size=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.41542216, 0.98174289]), array([-0.0688291 ,  0.29505787]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance because we want to determine steps and direction\n",
    "dist = np.linalg.norm(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide by stepsize to find number of steps to move\n",
    "# Doesn't need to be exact, just need the actual stepsize to be somewhat close\n",
    "# Which is why we're not bothering with traversing exact distances\n",
    "stepsize = 0.01\n",
    "stepcount = int(dist / stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then we pass to np.linspace to generate the steps\n",
    "# If np.arange supports array-like input, we don't need to bother w/\n",
    "# distance to get consistent step sizes\n",
    "steps = np.linspace(start, end, stepcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_ls(\n",
    "    dims=3, \n",
    "    init_coord=np.array([0, 0, 0]), \n",
    "    iterations=1000, \n",
    "    stepsize=0.01, \n",
    "    min_coord=np.array([-1, -1, -1]), \n",
    "    max_coord=np.array([1, 1, 1]), \n",
    "):\n",
    "    \"\"\"\n",
    "    Explore latent space by travelling to randomly selected point.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    dims: int\n",
    "    init_coord: iterable\n",
    "    iterations: int\n",
    "    stepsize: int\n",
    "    min_coord: iterable\n",
    "    max_coord: iterable\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    pos_arr: np.ndarray\n",
    "    path_lenghts: List[Int]\n",
    "    \"\"\"\n",
    "    # Check to ensure all inputs have the correct dimensions\n",
    "    assert len(init_coord) == dims\n",
    "    assert len(min_coord) == dims\n",
    "    assert len(max_coord) == dims\n",
    "    \n",
    "    # Transform all to numpy array\n",
    "    if not isinstance(init_coord, np.ndarray):\n",
    "        init_coord = np.array(init_coord)\n",
    "        \n",
    "    if not isinstance(min_coord, np.ndarray):\n",
    "        min_coord = np.array(min_coord)\n",
    "        \n",
    "    if not isinstance(max_coord, np.ndarray):\n",
    "        max_coord = np.array(max_coord)\n",
    "    \n",
    "    # Initialize list to store positions\n",
    "    pos_list = []\n",
    "    current_iterations = 0\n",
    "    path_lengths = []\n",
    "    current_point = init_coord\n",
    "    \n",
    "    # Iterate to find the probability thresholds\n",
    "    while current_iterations < iterations:\n",
    "        \n",
    "        # Find next point\n",
    "        next_point = np.random.uniform(low=min_coord, high=max_coord, size=(dims,))\n",
    "        \n",
    "        # Calculate distance because we want to determine steps and direction\n",
    "        dist = np.linalg.norm(next_point - current_point)\n",
    "        stepcount = int(dist / stepsize)\n",
    "        steps = np.linspace(current_point, next_point, stepcount)\n",
    "        \n",
    "        # Update\n",
    "        current_iterations += len(steps)\n",
    "        path_lengths.append(len(steps))\n",
    "        current_point = next_point\n",
    "        pos_list.append(steps)\n",
    "        \n",
    "    # Convert to array\n",
    "    pos_arr = np.concatenate(pos_list, axis=0)\n",
    "    \n",
    "    return pos_arr[:iterations], path_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, path_lengths = explore_ls(dims=3, init_coord=[0, 0, 0], iterations=10000, \n",
    "              stepsize=0.1, min_coord=[-1, -1, -1], max_coord=[1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code from previous notebook with added polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Describes a generative CPPN that takes `x`, `y`, and optionally distance to origin as input,\n",
    "    and outputs 3-channel / 1-channel pixel intensity.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hidden_layers=4,\n",
    "        num_neurons=8,\n",
    "        latent_len=3,\n",
    "        include_bias=True,\n",
    "        include_dist_to_origin=True,\n",
    "        rgb=True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the CPPN.\n",
    "\n",
    "        Inputs\n",
    "        ------\n",
    "        num_hidden_layers: int\n",
    "            Number of hidden layers in the network.\n",
    "\n",
    "        num_neurons: int\n",
    "            Number of neurons in each hidden layer.\n",
    "\n",
    "        latent_len: int\n",
    "            Length of latent vector\n",
    "\n",
    "        include_bias: bool\n",
    "            If True, includes bias term in input layer.\n",
    "\n",
    "        include_dist_to_origin: bool\n",
    "            If True, includes distance to origin as one of the inputs.\n",
    "\n",
    "        rgb: bool\n",
    "            If True, produces 3-channel output. Else, produces 1-channel output.\n",
    "\n",
    "        Output\n",
    "        ------\n",
    "        None\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Input layer\n",
    "        if include_dist_to_origin:\n",
    "            layers = [\n",
    "                nn.Linear(3 + latent_len, num_neurons, bias=include_bias),\n",
    "                nn.Tanh(),\n",
    "            ]\n",
    "        else:\n",
    "            layers = [\n",
    "                nn.Linear(2 + latent_len, num_neurons, bias=include_bias),\n",
    "                nn.Tanh(),\n",
    "            ]\n",
    "\n",
    "        # Hidden layers\n",
    "        layers.extend(\n",
    "            num_hidden_layers\n",
    "            * [\n",
    "                nn.Linear(num_neurons, num_neurons, bias=False),\n",
    "                nn.Tanh(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Output layer\n",
    "        if rgb:\n",
    "            layers.extend([nn.Linear(num_neurons, 3, bias=False), nn.Sigmoid()])\n",
    "        else:\n",
    "            layers.extend([nn.Linear(num_neurons, 1, bias=False), nn.Sigmoid()])\n",
    "\n",
    "        # Assign layers to self.layers\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "        # Run weight init\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, loc_vec, latent_vec):\n",
    "        \"\"\"\n",
    "        `forward` function for the generative network.\n",
    "\n",
    "        Input\n",
    "        -----\n",
    "        loc_vec, latent_vec: torch.Tensor\n",
    "            Location vector and latent vector.\n",
    "            Location vector should have shape (N, 2) or shape (N, 3).\n",
    "            Latent vector should have shape (N, `latent_len`)\n",
    "\n",
    "        Output\n",
    "        ------\n",
    "        x: torch.Tensor\n",
    "        \"\"\"\n",
    "        x = torch.cat([loc_vec, latent_vec], dim=1)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        \"\"\"\n",
    "        Function to apply to the generative network (literally with `Net.apply()`) to initialize\n",
    "        network weights properly. Required as the default initialization is for deep learning\n",
    "        training, while we're only interested in starting all layers with a normal distribution.\n",
    "\n",
    "        Ref: https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch\n",
    "\n",
    "        Input\n",
    "        -----\n",
    "        m: nn.Modules (I think)\n",
    "\n",
    "        Output\n",
    "        ------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.normal_(m.weight, mean=0, std=1)\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        Initializes the weights of the network.\n",
    "\n",
    "        Input\n",
    "        -----\n",
    "        None\n",
    "\n",
    "        Output\n",
    "        ------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.apply(self._init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input(img_width, img_height, include_dist_to_origin=True):\n",
    "    \"\"\"\n",
    "    Creates the input for the generative net.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    img_width, img_height: int\n",
    "    include_dist_to_origin: bool\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    input_arr: np.ndarray\n",
    "        Should have shape (img_width * img_height, 2)\n",
    "    \"\"\"\n",
    "    # Create vectors of xs and ys\n",
    "    xs = np.linspace(start=-1, stop=1, num=img_width)\n",
    "    ys = np.linspace(start=-1, stop=1, num=img_height)\n",
    "\n",
    "    # Use np.meshgrid to create a mesh grid\n",
    "    xv, yv = np.meshgrid(xs, ys)\n",
    "    input_arr = np.stack((xv, yv), axis=2)\n",
    "\n",
    "    if include_dist_to_origin:\n",
    "        dist_to_origin = np.sum(np.square(input_arr), axis=2, keepdims=True)\n",
    "        input_arr = np.concatenate([input_arr, dist_to_origin], axis=2)\n",
    "        input_arr = input_arr.reshape(img_width * img_height, 3)\n",
    "    else:\n",
    "        input_arr = input_arr.reshape(img_width * img_height, 2)\n",
    "\n",
    "    return input_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_one_art(\n",
    "    net, latent_vec, input_config={\"img_width\": 320, \"img_height\": 320}\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper function to generate a single image output from the given network.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    net: Net\n",
    "    latent_vec: torch.Tensor\n",
    "    input_config: dict\n",
    "        Dict of parameters to be passed to `create_input` as kwargs.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    net_output: np.ndarray\n",
    "        Should have shape (y, x, 3) or (y, x, 1)\n",
    "    \"\"\"\n",
    "    # Create input to net, and convert from ndarray to torch.FloatTensor\n",
    "    net_input = torch.tensor(create_input(**input_config)).float()\n",
    "\n",
    "    # Create input array from latent_vec, and convert from ndarray to torch.FloatTensor\n",
    "    latent_vec = np.expand_dims(latent_vec, axis=0)\n",
    "    latent_vec = np.repeat(latent_vec, repeats=net_input.shape[0], axis=0)\n",
    "    latent_vec = torch.tensor(latent_vec).float()\n",
    "\n",
    "    assert net_input.shape == latent_vec.shape\n",
    "\n",
    "    # Run input through net\n",
    "    net_output = net(net_input, latent_vec).detach().numpy()\n",
    "\n",
    "    # Reshape into (y, x, 3) for plotting in PIL\n",
    "    net_output = net_output.reshape(\n",
    "        input_config[\"img_height\"], input_config[\"img_width\"], -1\n",
    "    )\n",
    "\n",
    "    # Re-format to color output\n",
    "    # Scale to range 0 to 255, and set type to int\n",
    "    net_output = (net_output * 255).astype(np.uint8)\n",
    "    return net_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore latent space with random walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 63, 60, 46, 82]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [01:12<00:00,  3.32it/s]\n"
     ]
    }
   ],
   "source": [
    "total_seconds = 10\n",
    "fps = 24\n",
    "iterations = total_seconds * fps\n",
    "\n",
    "latent_arr, path_lengths = explore_ls(\n",
    "    iterations=iterations, min_coord=[-2, -2, -2], max_coord=[2, 2, 2], stepsize=0.05\n",
    ")\n",
    "print(path_lengths)\n",
    "net = Net(num_hidden_layers=2, num_neurons=64)\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "    out = generate_one_art(net, latent_vec=latent_arr[i], input_config={\"img_width\": 640, \"img_height\": 320})\n",
    "    imgs.append(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoWriter(\"../output/tour-latent-space.avi\", cv2.VideoWriter_fourcc(*'XVID'), 24, (640, 320))\n",
    "for image in imgs:\n",
    "    video.write(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh yeah this is a lot better. \n",
    "\n",
    "The shift in direction is a bit abrupt, probably possible to incorporate some kind of deceleration and acceleration while transitioning between points. Even better would be to fit splines, though from preliminary Googling, `scipy` has implementations only for 1D and 2D splines. Went off on a tangent reading about motion control profiles, decided to keep it simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.20408163,  0.40816327,  0.6122449 ,  0.81632653,\n",
       "        1.02040816,  1.2244898 ,  1.42857143,  1.63265306,  1.83673469,\n",
       "        2.04081633,  2.24489796,  2.44897959,  2.65306122,  2.85714286,\n",
       "        3.06122449,  3.26530612,  3.46938776,  3.67346939,  3.87755102,\n",
       "        4.08163265,  4.28571429,  4.48979592,  4.69387755,  4.89795918,\n",
       "        5.10204082,  5.30612245,  5.51020408,  5.71428571,  5.91836735,\n",
       "        6.12244898,  6.32653061,  6.53061224,  6.73469388,  6.93877551,\n",
       "        7.14285714,  7.34693878,  7.55102041,  7.75510204,  7.95918367,\n",
       "        8.16326531,  8.36734694,  8.57142857,  8.7755102 ,  8.97959184,\n",
       "        9.18367347,  9.3877551 ,  9.59183673,  9.79591837, 10.        ])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.        ,  9.25874712,  8.57243983,  7.93700526,  7.34867246,\n",
       "        6.80395   ,  6.29960525,  5.8326452 ,  5.40029869,  5.        ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(np.log10(10), np.log10(5), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_ls(\n",
    "    dims=3, \n",
    "    init_coord=np.array([0, 0, 0]), \n",
    "    iterations=1000, \n",
    "    stepsize=0.01, \n",
    "    min_coord=np.array([-1, -1, -1]), \n",
    "    max_coord=np.array([1, 1, 1]), \n",
    "    smooth_start_stop=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Explore latent space by travelling to a randomly selected point. \n",
    "    This process is repeated until the number of steps as specified by\n",
    "    `iterations` is exceeded, of which the steps are truncated and \n",
    "    returned together with the path lengths.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    dims: int\n",
    "    init_coord: iterable\n",
    "    iterations: int\n",
    "    stepsize: int\n",
    "    min_coord: iterable\n",
    "    max_coord: iterable\n",
    "    smooth_start_stop: bool\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    pos_arr: np.ndarray\n",
    "    path_lengths: List[Int]\n",
    "    \"\"\"\n",
    "    # Check to ensure all inputs have the correct dimensions\n",
    "    assert len(init_coord) == dims\n",
    "    assert len(min_coord) == dims\n",
    "    assert len(max_coord) == dims\n",
    "    \n",
    "    # Transform all to numpy array\n",
    "    if not isinstance(init_coord, np.ndarray):\n",
    "        init_coord = np.array(init_coord)\n",
    "        \n",
    "    if not isinstance(min_coord, np.ndarray):\n",
    "        min_coord = np.array(min_coord)\n",
    "        \n",
    "    if not isinstance(max_coord, np.ndarray):\n",
    "        max_coord = np.array(max_coord)\n",
    "    \n",
    "    # Initialize list to store positions\n",
    "    pos_list = []\n",
    "    current_iterations = 0\n",
    "    path_lengths = []\n",
    "    current_point = init_coord\n",
    "    \n",
    "    # Iterate to find the probability thresholds\n",
    "    while current_iterations < iterations:\n",
    "        \n",
    "        # Find next point\n",
    "        next_point = np.random.uniform(low=min_coord, high=max_coord, size=(dims,))\n",
    "        \n",
    "        # Calculate distance because we want to determine steps and direction\n",
    "        dist = np.linalg.norm(next_point - current_point)\n",
    "        stepcount = int(dist / stepsize)\n",
    "        steps = np.linspace(current_point, next_point, stepcount)\n",
    "        \n",
    "        # Smooth decel and accel\n",
    "        if smooth_start_stop is True:\n",
    "            # Decel final 20% of path\n",
    "            # 80% to 90% runs at 1.5x steps\n",
    "            # 90% to 100% runs at 3x steps\n",
    "            decel_point1 = int(stepcount * 0.8)\n",
    "            decel_point2 = int(stepcount * 0.9)\n",
    "            decel_path1 = np.linspace(\n",
    "                steps[decel_point1],\n",
    "                steps[decel_point2], \n",
    "                int(1.5 * (decel_point2 - decel_point1))\n",
    "            )\n",
    "            decel_path2 = np.linspace(\n",
    "                steps[decel_point2],\n",
    "                steps[-1], \n",
    "                int(3 * (stepcount - decel_point2))\n",
    "            )\n",
    "\n",
    "            # Accel first 10% of path\n",
    "            # 0% to 10% stretched into 3x steps\n",
    "            # 10% to 20% stretched into 1.5x steps\n",
    "            # Pretty much reverse of above\n",
    "            accel_point1 = int(stepcount * 0.1)\n",
    "            accel_point2 = int(stepcount * 0.2)\n",
    "            accel_path1 = np.linspace(\n",
    "                steps[0],\n",
    "                steps[accel_point1], \n",
    "                int(3 * (accel_point1 - 0))\n",
    "            )\n",
    "            accel_path2 = np.linspace(\n",
    "                steps[accel_point1],\n",
    "                steps[accel_point2], \n",
    "                int(1.5 * (accel_point2 - accel_point1))\n",
    "            )\n",
    "\n",
    "            steps = np.concatenate([\n",
    "                accel_path1, accel_path2,\n",
    "                steps[accel_point2:decel_point1],\n",
    "                decel_path1, decel_path2\n",
    "            ])\n",
    "            \n",
    "        \n",
    "        # Update\n",
    "        current_iterations += len(steps)\n",
    "        path_lengths.append(len(steps))\n",
    "        current_point = next_point\n",
    "        pos_list.append(steps)\n",
    "        \n",
    "    # Convert to array\n",
    "    pos_arr = np.concatenate(pos_list, axis=0)\n",
    "    \n",
    "    return pos_arr[:iterations], path_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70, 71, 114]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [01:09<00:00,  3.48it/s]\n"
     ]
    }
   ],
   "source": [
    "total_seconds = 10\n",
    "fps = 24\n",
    "iterations = total_seconds * fps\n",
    "\n",
    "latent_arr, path_lengths = explore_ls(\n",
    "    iterations=iterations, min_coord=[-2, -2, -2], max_coord=[2, 2, 2], stepsize=0.03\n",
    ")\n",
    "print(path_lengths)\n",
    "net = Net(num_hidden_layers=2, num_neurons=64)\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "    out = generate_one_art(net, latent_vec=latent_arr[i], input_config={\"img_width\": 640, \"img_height\": 320})\n",
    "    imgs.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoWriter(\"../output/tour-latent-space.avi\", cv2.VideoWriter_fourcc(*'XVID'), 24, (640, 320))\n",
    "for image in imgs:\n",
    "    video.write(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm this is a slight improvement, would really still prefer the path to be a smooth spline. Either way, this is good enough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn-gen-art]",
   "language": "python",
   "name": "conda-env-nn-gen-art-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
